{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bee66f-58ca-4af3-bcec-a3f3663ed5f3",
   "metadata": {},
   "source": [
    "# Deep dive into Pandas Series data structure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b2060-326e-494c-8fd5-228facd463c4",
   "metadata": {},
   "source": [
    "**Read the official documentation on pandas Series objects @ https://pandas.pydata.org/pandas-docs/stable/reference/series.html**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee0640-cf64-4a48-96d3-4578bea333e6",
   "metadata": {},
   "source": [
    "**Note:** We can actually use pythons built in functions on pandas series objects. i.e., len, type, dir, in, sum, product, mean, sorted, max, min etc. Also, the notion of chaining functions/methods in pandas is similar to python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3180c09-a72e-4412-9b46-9e1b7502c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e722997-70c9-47c7-8f93-122d0d731de0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---------------------------\n",
    "### Importing the data\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759735df-a8d1-4b04-9616-f3bc9ba6b5ba",
   "metadata": {},
   "source": [
    "One of the datasets we will use for our examples in this notebook is the `/Data/vehicles.csv.zip` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39832f0-85bc-4ff0-a7c7-7f090a8cc633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14574/4195767653.py:2: DtypeWarning: Columns (68,70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Data/vehicles.csv.zip\")\n"
     ]
    }
   ],
   "source": [
    "# read the vehicles.csv dataset\n",
    "df = pd.read_csv(\"Data/vehicles.csv.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622916c-066f-4888-8d56-0ff73d224fb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---------------------------------------------\n",
    "## Mathematical operations and Index Alignment \n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5987dc-acd4-41c9-88e4-c538d66e1e27",
   "metadata": {},
   "source": [
    "> The mathematical operations that are available include: **+, -, /, // (floor division), % (modulus), @ (matrix multiplication), ** (power), <, <=, ==, !=, >=, >, & (binary and), ^ (binary xor), | (binary or).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9ab5c-8ea0-43cf-a32e-2b13c8df9be9",
   "metadata": {},
   "source": [
    "However, pandas will **align the index** before performing any of these operations. Aligning will take each index entry in the left series and match it up with every entry with the same name in the index of the right series. Because of index alignment, you will want to **make sure that the indexes are, unique (no duplicates) and, common to both series**. Otherwise, the produced result will not be as expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0b8b7-5c35-48b4-81a1-0a2f5e9bae3c",
   "metadata": {},
   "source": [
    "- Example of how index alignment can cause to produce unintended results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0452a18-107e-4d2c-8e48-f00f2dd8221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([10, 20, 30], index=[1, 2, 2])\n",
    "s2 = pd.Series([15, 28, 32], index=[2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7aea1f1-c3c4-4476-8a93-ae964d633f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     NaN\n",
       "2    35.0\n",
       "2    48.0\n",
       "2    45.0\n",
       "2    58.0\n",
       "3     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95602cd5-3f57-421b-91bc-74d52ad63d95",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96f0ae-f0ba-4972-be28-778aa74b49bc",
   "metadata": {},
   "source": [
    "Note that, index-1 and index-3 has NaN values whereas, for index-2, every index-2 value from s1 is matched with every index-2 value from s2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d541a5f-8208-4202-b954-94f6680cc655",
   "metadata": {},
   "source": [
    "- **Operator methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba109c04-9358-4c6c-ae79-df8fb400ac93",
   "metadata": {},
   "source": [
    "Pandas also provides **operator methods** for each of the mathematical operations. The benefit is, the operator methods have a **fill_value** parameter that can change the default behavior. **By default, the operator methods will produce the same output as the mathematical operators themselves. But, if a fill_value is defined then when one of the operands is missing, the method will use the fill_value instead.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367524-0b15-4c06-b683-3b00a7250417",
   "metadata": {},
   "source": [
    "> Some of the operator methods include: **add, sub, mul, div, mod, pow, rfloordiv, lt, gt, eq, ne, le, ge, dot, product** etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2df622-57a9-44c7-a945-ca5f8af50821",
   "metadata": {},
   "source": [
    "For instance, in the above example if we wanted to have values at index-1 and index-3 instead of NaN values we can use the **s1.add(s2, fill_value=0)** method. Probably, you can already guess how this will work out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996e7002-175b-4909-8d56-4fdc397355d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10.0\n",
       "2    35.0\n",
       "2    48.0\n",
       "2    45.0\n",
       "2    58.0\n",
       "3    32.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the add() method to add the elements of both series with fill_value=0\n",
    "s1.add(s2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52208edb-a66f-4d79-b41f-0894fb00b268",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46435425-e19f-4928-bfd4-636ca47d4938",
   "metadata": {},
   "source": [
    "Learn about all the available operator methods @ https://pandas.pydata.org/pandas-docs/stable/reference/series.html#binary-operator-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7605b8c-004b-4da0-92dd-d30ca61a7887",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---------------------------------------------\n",
    "## Aggregate methods \n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5c124-9c96-45ef-8bdd-11b28abc0576",
   "metadata": {},
   "source": [
    "Aggregate methods collapse the values of a series down to a scalar. Thus, allowing you to take detailed data and collapse it to a single value e.g, sum, count, mean, median etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097f5e2-1c36-4c2a-ba2a-c39d899aad51",
   "metadata": {},
   "source": [
    "> Some of the commonly used aggregate methods are, **all, any, count, prod, min, max, nsmallest, nlargest, cummax, cumsum, cumprod, mean, median, mode, sum, std, var, quantile, unique, nunique, value_counts, describe** etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a4e491-386a-4837-9e7c-5cd1189b57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the city08 and highway08 columns from the vehicles.csv dataset\n",
    "# provide information on miles per gallon usage while driving around in the city and highway respectively.\n",
    "city_mpg = df.city08\n",
    "highway_mpg = df.highway08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639ae01-2960-4063-9c63-2dd4905b3d55",
   "metadata": {},
   "source": [
    "- Counting non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615eb8a7-75d0-41ef-b740-6bb26f22041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of non-NA vals: 41144\n"
     ]
    }
   ],
   "source": [
    "# Count total number of non-NA/null values in a series\n",
    "print(\"no of non-NA vals:\", city_mpg.count())\n",
    "\n",
    "# but if we use count as an attribute then this will return a series containing the non-NA values\n",
    "\n",
    "# city_mpg.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335acfe8-f8f7-4630-997b-5050af435494",
   "metadata": {},
   "source": [
    "- Largest n elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7611905-5a86-4e99-b26a-07c52f7aa76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 largest values: \n",
      " 31256    150\n",
      "32599    150\n",
      "33423    150\n",
      "Name: city08, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# return the largest n values\n",
    "print(\"3 largest values: \\n\", city_mpg.nlargest(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3eed21-adf3-43cf-9323-d2e96b2d22ac",
   "metadata": {},
   "source": [
    "- Cumilitive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1caac5ae-c42e-44c0-879b-81e6e4714f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41139    755704\n",
       "41140    755724\n",
       "41141    755742\n",
       "41142    755760\n",
       "41143    755776\n",
       "Name: city08, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cumilitive sum of a series\n",
    "city_mpg.cumsum().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71493d-7d87-44c3-8d67-9ae2ce4ed516",
   "metadata": {},
   "source": [
    "- Quantile values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7101d-bf74-490f-b050-ec85e6badf2f",
   "metadata": {},
   "source": [
    "Quantile is where probability distribution is divided into areas of equal probability. If we consider percentages, we first divide the distribution into 100 pieces. When we look into PDF, the 5th quantile is the point that cuts off an area of 5% in the lower tail of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44dcbbc3-8d89-482f-b3ee-8dfdf32c0ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25    15.0\n",
       "0.50    17.0\n",
       "0.75    20.0\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantile by default returns the 50% quantile. We can also pass in a list. In such case, this will return a series object\n",
    "city_mpg.quantile([0.25, 0.5, 0.75])  # 25%, 50% and 75% quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8910ecb3-6f2d-4641-90af-a4e0599f8cb1",
   "metadata": {},
   "source": [
    "- Generate descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a05c69-acfb-4b71-986a-9b797de77455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    41144.000000\n",
       "mean        18.369045\n",
       "std          7.905886\n",
       "min          6.000000\n",
       "25%         15.000000\n",
       "50%         17.000000\n",
       "75%         20.000000\n",
       "max        150.000000\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d40382-382f-44e3-ab8c-2065b8aa1ce5",
   "metadata": {},
   "source": [
    "- Unique values in a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432a58e8-007a-46bd-b640-f3d5a79129ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19,   9,  23,  10,  17,  21,  22,  18,  12,  20,  14,  11,  15,\n",
       "        13,  16,  25,  24,  26,  31,  27,  30,  38,  28,  43,  35,  33,\n",
       "        29,  39,  37,   8,   7,  34,  32,  36,  49,  81,  45,  48,  42,\n",
       "         6,  44,  74,  84,  40,  87,  41,  51,  62,  59,  79,  50,  52,\n",
       "       102, 106,  94, 126,  53, 107,  77, 110,  88, 132, 122, 138,  78,\n",
       "        60,  47, 129,  93, 128,  61, 137,  85, 120,  86,  89,  95, 101,\n",
       "        90, 124, 121,  54,  58,  91,  97,  73,  98,  92, 150,  55,  57,\n",
       "        46, 118, 112, 131, 136,  83, 125,  80, 123, 127, 114, 140, 115,\n",
       "       104])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return unique values in a series as ndarray\n",
    "city_mpg.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f0f0b9-2305-4746-9b30-e69758c88f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15     4503\n",
       "18     4053\n",
       "17     4035\n",
       "16     3975\n",
       "19     3012\n",
       "       ... \n",
       "127       1\n",
       "114       1\n",
       "140       1\n",
       "115       1\n",
       "104       1\n",
       "Name: city08, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a series containing counts of unique values\n",
    "city_mpg.value_counts(dropna=False)  # by default, dropna=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20034f31-94aa-4a49-bdf1-c41e67097031",
   "metadata": {},
   "source": [
    "### The _.agg()_ function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065af75d-33ae-46b7-a63f-b4e1fea97258",
   "metadata": {},
   "source": [
    "The `.agg()` function can be used to perform multiple aggregate operations (you can also define your own aggregate functions) on a series object at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b099dd-25ae-4941-8d50-b624d1d51539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min                 6\n",
       "idxmin           7901\n",
       "max               150\n",
       "idxmax          31256\n",
       "mean        18.369045\n",
       "std          7.905886\n",
       "var         62.503036\n",
       "quantile         17.0\n",
       "all              True\n",
       "sum            755776\n",
       "Name: city08, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.agg(\n",
    "    [\"min\", \"idxmin\", \"max\", \"idxmax\", \"mean\", \"std\", \"var\", \"quantile\", \"all\", \"sum\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0727ccc-aa34-4bf1-ab1e-957bf1f267a1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf18a7-09e3-4b1e-a622-1fb169c57a23",
   "metadata": {},
   "source": [
    "To learn about all the available aggregate functions see the documentation @ https://pandas.pydata.org/pandas-docs/stable/reference/series.html#computations-descriptive-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43602c69-054c-4dc3-8bff-79fa00ed0443",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------------------------\n",
    "## Data type casting \n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb58136-d947-4172-a712-c6a4969bd31c",
   "metadata": {},
   "source": [
    "It is often the case that we need to convert between data types, usually for better performance (more manipulation\n",
    "options or use less memory) or some other reasons. Whatever may be the case Pandas provides a very useful function namely, `astype(dtype)` for converting data type of a Series or DataFrame object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b5fa69-b15a-405e-bdab-2a89db06dd79",
   "metadata": {},
   "source": [
    "> Some of the major datatypes available in pandas include: **object, int, float, bool, datetime, category** etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f2ce2-148f-4dbd-b66b-290e2d492655",
   "metadata": {},
   "source": [
    "Refer to this article @ https://pbpython.com/pandas_dtypes.html for a basic idea on the pandas data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776a918-06c0-4301-b30d-954f0a64d362",
   "metadata": {},
   "source": [
    "- Inspecting numerical limits of different integer and float types "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e495e9-f7c7-4310-97f4-8e214f6c93a9",
   "metadata": {},
   "source": [
    "The **default numeric type is 8 bytes wide (64 bits, ie int64 or float64)**. If you can use a narrower type, you can cut back on memory usage, giving you memory to process more data. You can use NumPy to inspect limits on integer and float types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a856147d-f5e7-4cc9-81c2-b2686b03b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for int16\n",
      "---------------------------------------------------------------\n",
      "min = -32768\n",
      "max = 32767\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for uint8\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 255\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# integer\n",
    "print(np.iinfo(np.int16))  # or, np.iinfo(\"int16\")\n",
    "print(np.iinfo(np.uint8))  # or, np.iinfo(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "137af9df-c46b-43d1-b690-8a15a752911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for float16\n",
      "---------------------------------------------------------------\n",
      "precision =   3   resolution = 1.00040e-03\n",
      "machep =    -10   eps =        9.76562e-04\n",
      "negep =     -11   epsneg =     4.88281e-04\n",
      "minexp =    -14   tiny =       6.10352e-05\n",
      "maxexp =     16   max =        6.55040e+04\n",
      "nexp =        5   min =        -max\n",
      "smallest_normal = 6.10352e-05   smallest_subnormal = 5.96046e-08\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# float\n",
    "print(np.finfo(\"float16\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5081d73d-8bce-4cb7-9e46-5f9bb8893f00",
   "metadata": {},
   "source": [
    "- Checking memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5590c-a42c-41de-8495-c5ec59f0cdfa",
   "metadata": {},
   "source": [
    "To check how much memory the values of a Series or DataFrame is consuming we can use the `nbytes` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df999628-11cc-41cb-9333-26bd97a7e239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246864"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, the data in city_mpg Series was stored as int64 type\n",
    "\n",
    "# the max value in our seires object is 150\n",
    "# so, we can't use int8 but we can cast to int16\n",
    "\n",
    "# to see how much space is saved\n",
    "city_mpg.nbytes - city_mpg.astype(\"int16\").nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb0729-1e4b-4d26-b28e-b06ea6156ea0",
   "metadata": {},
   "source": [
    "Using `.nbytes` with object types only shows how much memory the Pandas object is taking. The **make** in the vehicles dataset provides the manufacturer name (strings) and is stored as an object. To get the amount of memory that includes the strings, we need to use the `.memory_usage` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1747473-933f-4a96-a32e-348f38781d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the make column as a series\n",
    "manufac = df.make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dbd9567-6b46-4aab-90a7-ffbebfcb8491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Alfa Romeo\n",
       "1       Ferrari\n",
       "2         Dodge\n",
       "Name: make, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manufac.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d437ac04-d930-45fb-829c-03d70e0fef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329152"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining memory usage with nbbytes function\n",
    "manufac.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b092780c-5a51-41c4-a667-fe94b2f05afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2606395"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining memory usage with memory_usage function\n",
    "manufac.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4a529-6ef1-4ca0-b289-f1d2d879da55",
   "metadata": {},
   "source": [
    "The value of _.nbytes_ is just the memory that the data is using and not the ancillary parts of the Series. The _.memory_usage_ includes the index memory and can include the contribution from object types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c740b-fc4f-4c5a-aa6b-699189a20f76",
   "metadata": {},
   "source": [
    "- **String and Category types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521d54f-fa5b-4cf5-ace9-3e55b4f0f8df",
   "metadata": {},
   "source": [
    "A `categorical` series is useful for string data and can result in large memory savings. This is because for categorical data, instead of using python `string` to store the values, pandas optimizes it so that **repeating values are not duplicated**. You **still have all of the functionality found off of the .str attribute.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72b1d9-58ca-42fc-abdf-3cf3b4e0ff06",
   "metadata": {},
   "source": [
    "For example, if we convert the make column from the vehicles dataframe i.e, the manufac series to category object, this will have much more improved memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d15fb8e8-ae21-4c4e-87e7-860d8087ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the make column as categorical object\n",
    "manufac_cat = df.make.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14dbff7e-603e-45ae-9ce0-1aeed8a13cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Alfa Romeo\n",
       "1       Ferrari\n",
       "2         Dodge\n",
       "Name: make, dtype: category\n",
       "Categories (136, object): ['AM General', 'ASC Incorporated', 'Acura', 'Alfa Romeo', ..., 'Volvo', 'Wallace Environmental', 'Yugo', 'smart']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manufac_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77576bdc-47a8-41f2-9a3a-ed312ab84409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241608"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the memory footprint\n",
    "manufac.memory_usage() - manufac_cat.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94ca01-e613-4f41-a36a-bc226958f7fe",
   "metadata": {},
   "source": [
    "- **Custom & ordered categories**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d2bd6-9d6b-4fe3-9ec4-b33792391058",
   "metadata": {},
   "source": [
    "To create ordered categories, we need to use the `pd.Categorical(values, categories, ordered=False)` function.\n",
    "**Note:**\n",
    "1. a Categorical **might have an order**, but numerical operations (additions, divisions, ...) are not possible.    \n",
    "2. Assigning values **outside of categories** will result in replacing the value with **NaN** in the series object.\n",
    "3. Order is defined by the order of the categories, **not lexical order** of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e86ebf-503d-4d51-bc4e-351999956dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values\n",
    "vals = manufac\n",
    "# categories\n",
    "cat = manufac.unique()\n",
    "\n",
    "# to have an ordered category we just need to set, ordered = True\n",
    "ord_manufac = pd.Categorical(values=vals, categories=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6150ad4-f065-4417-9be5-d2e3a9af19b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alfa Romeo', 'Ferrari', 'Dodge', 'Dodge', 'Subaru', ..., 'Subaru', 'Subaru', 'Subaru', 'Subaru', 'Subaru']\n",
       "Length: 41144\n",
       "Categories (136, object): ['Alfa Romeo', 'Ferrari', 'Dodge', 'Subaru', ..., 'Consulier Industries Inc', 'Goldacre', 'Isis Imports Ltd', 'PAS Inc - GMC']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_manufac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69aa5e-7902-4c45-9d51-714d1a517e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
