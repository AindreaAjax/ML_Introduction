{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bee66f-58ca-4af3-bcec-a3f3663ed5f3",
   "metadata": {},
   "source": [
    "# Deep dive into Pandas Series data structure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2b2060-326e-494c-8fd5-228facd463c4",
   "metadata": {},
   "source": [
    "**Read the official documentation on pandas Series objects @ https://pandas.pydata.org/pandas-docs/stable/reference/series.html**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee0640-cf64-4a48-96d3-4578bea333e6",
   "metadata": {},
   "source": [
    "**Note:** We can actually use pythons built in functions on pandas series objects. i.e., len, type, dir, in, sum, product, mean, sorted, max, min etc. Also, the notion of chaining functions/methods in pandas is similar to python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3180c09-a72e-4412-9b46-9e1b7502c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e722997-70c9-47c7-8f93-122d0d731de0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---------------------------\n",
    "### Importing the data\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759735df-a8d1-4b04-9616-f3bc9ba6b5ba",
   "metadata": {},
   "source": [
    "One of the datasets we will use for our examples in this notebook is the `/Data/vehicles.csv.zip` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39832f0-85bc-4ff0-a7c7-7f090a8cc633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12902/4195767653.py:2: DtypeWarning: Columns (68,70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Data/vehicles.csv.zip\")\n"
     ]
    }
   ],
   "source": [
    "# read the vehicles.csv dataset\n",
    "df = pd.read_csv(\"Data/vehicles.csv.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622916c-066f-4888-8d56-0ff73d224fb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---------------------------------------------\n",
    "## Mathematical operations and Index Alignment \n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5987dc-acd4-41c9-88e4-c538d66e1e27",
   "metadata": {},
   "source": [
    "> The mathematical operations that are available include: \n",
    "\n",
    "    +, -, /, // (floor division), % (modulus), @ (matrix multiplication), ** (power), <, <=, ==, !=, >=, >, & (binary and), ^ (binary xor), | (binary or)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9ab5c-8ea0-43cf-a32e-2b13c8df9be9",
   "metadata": {},
   "source": [
    "However, pandas will **align the index** before performing any of these operations. Aligning will take each index entry in the left series and match it up with every entry with the same name in the index of the right series. Because of index alignment, you will want to **make sure that the indexes are, unique (no duplicates) and, common to both series**. Otherwise, the produced result will not be as expected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0b8b7-5c35-48b4-81a1-0a2f5e9bae3c",
   "metadata": {},
   "source": [
    "- Example of how index alignment can cause to produce unintended results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0452a18-107e-4d2c-8e48-f00f2dd8221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([10, 20, 30], index=[1, 2, 2])\n",
    "s2 = pd.Series([15, 28, 32], index=[2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7aea1f1-c3c4-4476-8a93-ae964d633f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     NaN\n",
       "2    35.0\n",
       "2    48.0\n",
       "2    45.0\n",
       "2    58.0\n",
       "3     NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 + s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95602cd5-3f57-421b-91bc-74d52ad63d95",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96f0ae-f0ba-4972-be28-778aa74b49bc",
   "metadata": {},
   "source": [
    "Note that, index-1 and index-3 has NaN values. Whereas, for index-2, every index-2 value from s1 is matched with every index-2 value from s2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d541a5f-8208-4202-b954-94f6680cc655",
   "metadata": {},
   "source": [
    "- **Operator methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba109c04-9358-4c6c-ae79-df8fb400ac93",
   "metadata": {},
   "source": [
    "Pandas also provides **operator methods** for each of the mathematical operations. The benefit is, the operator methods have a **fill_value** parameter that can change the default behavior. **By default, the operator methods will produce the same output as the mathematical operators themselves. But, if a fill_value is defined then, when one of the operands is missing, the method will use the fill_value instead.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367524-0b15-4c06-b683-3b00a7250417",
   "metadata": {},
   "source": [
    "> Some of the operator methods include: \n",
    "    \n",
    "    add(), sub(), mul(), div(), mod(), pow(), rfloordiv(), lt(), gt(), eq(), ne(), le(), ge(), dot(), product() etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2df622-57a9-44c7-a945-ca5f8af50821",
   "metadata": {},
   "source": [
    "For instance, in the above example if we wanted to have values at index-1 and index-3 instead of NaN values we can use the **s1.add(s2, fill_value=0)** method. Probably, you can already guess how this will work out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996e7002-175b-4909-8d56-4fdc397355d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10.0\n",
       "2    35.0\n",
       "2    48.0\n",
       "2    45.0\n",
       "2    58.0\n",
       "3    32.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the add() method to add the elements of both series with fill_value=0\n",
    "s1.add(s2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52208edb-a66f-4d79-b41f-0894fb00b268",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46435425-e19f-4928-bfd4-636ca47d4938",
   "metadata": {},
   "source": [
    "Learn about all the available operator methods @ https://pandas.pydata.org/pandas-docs/stable/reference/series.html#binary-operator-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7605b8c-004b-4da0-92dd-d30ca61a7887",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---------------------------------------------\n",
    "## Aggregate methods \n",
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5c124-9c96-45ef-8bdd-11b28abc0576",
   "metadata": {},
   "source": [
    "Aggregate methods collapse the values of a series down to a scalar. Thus, allowing you to take detailed data and collapse it to a single value e.g, sum, count, mean, median etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097f5e2-1c36-4c2a-ba2a-c39d899aad51",
   "metadata": {},
   "source": [
    "> Some of the commonly used aggregate methods are, \n",
    "\n",
    "    all(), any(), count(), prod(), min(), max(), nsmallest(), nlargest(), cummax(), cumsum(), cumprod(), mean(), median(), mode(), sum(), std(), var(), quantile(), unique(), nunique(), value_counts(), describe() etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a4e491-386a-4837-9e7c-5cd1189b57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the city08 and highway08 columns from the vehicles.csv dataset\n",
    "# provide information on miles per gallon usage while driving around in the city and highway respectively.\n",
    "city_mpg = df.city08\n",
    "highway_mpg = df.highway08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639ae01-2960-4063-9c63-2dd4905b3d55",
   "metadata": {},
   "source": [
    "- Counting non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615eb8a7-75d0-41ef-b740-6bb26f22041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of non-NA vals: 41144\n"
     ]
    }
   ],
   "source": [
    "# Count total number of non-NA/null values in a series\n",
    "print(\"no of non-NA vals:\", city_mpg.count())\n",
    "\n",
    "# but if we use count as an attribute then this will return a series containing the non-NA values\n",
    "\n",
    "# city_mpg.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335acfe8-f8f7-4630-997b-5050af435494",
   "metadata": {},
   "source": [
    "- Largest n elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7611905-5a86-4e99-b26a-07c52f7aa76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 largest values: \n",
      " 31256    150\n",
      "32599    150\n",
      "33423    150\n",
      "Name: city08, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# return the largest n values\n",
    "print(\"3 largest values: \\n\", city_mpg.nlargest(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3eed21-adf3-43cf-9323-d2e96b2d22ac",
   "metadata": {},
   "source": [
    "- Cumilitive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1caac5ae-c42e-44c0-879b-81e6e4714f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41139    755704\n",
       "41140    755724\n",
       "41141    755742\n",
       "41142    755760\n",
       "41143    755776\n",
       "Name: city08, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cumilitive sum of a series\n",
    "city_mpg.cumsum().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71493d-7d87-44c3-8d67-9ae2ce4ed516",
   "metadata": {},
   "source": [
    "- Quantile values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7101d-bf74-490f-b050-ec85e6badf2f",
   "metadata": {},
   "source": [
    "Quantile is where probability distribution is divided into areas of equal probability. If we consider percentages, we first divide the distribution into 100 pieces. When we look into PDF, the 5th quantile is the point that cuts off an area of 5% in the lower tail of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44dcbbc3-8d89-482f-b3ee-8dfdf32c0ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25    15.0\n",
       "0.50    17.0\n",
       "0.75    20.0\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantile by default returns the 50% quantile. We can also pass in a list. In such case, this will return a series object\n",
    "city_mpg.quantile([0.25, 0.5, 0.75])  # 25%, 50% and 75% quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8910ecb3-6f2d-4641-90af-a4e0599f8cb1",
   "metadata": {},
   "source": [
    "- Generate descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90a05c69-acfb-4b71-986a-9b797de77455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    41144.000000\n",
       "mean        18.369045\n",
       "std          7.905886\n",
       "min          6.000000\n",
       "25%         15.000000\n",
       "50%         17.000000\n",
       "75%         20.000000\n",
       "max        150.000000\n",
       "Name: city08, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d40382-382f-44e3-ab8c-2065b8aa1ce5",
   "metadata": {},
   "source": [
    "- Unique values in a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432a58e8-007a-46bd-b640-f3d5a79129ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 19,   9,  23,  10,  17,  21,  22,  18,  12,  20,  14,  11,  15,\n",
       "        13,  16,  25,  24,  26,  31,  27,  30,  38,  28,  43,  35,  33,\n",
       "        29,  39,  37,   8,   7,  34,  32,  36,  49,  81,  45,  48,  42,\n",
       "         6,  44,  74,  84,  40,  87,  41,  51,  62,  59,  79,  50,  52,\n",
       "       102, 106,  94, 126,  53, 107,  77, 110,  88, 132, 122, 138,  78,\n",
       "        60,  47, 129,  93, 128,  61, 137,  85, 120,  86,  89,  95, 101,\n",
       "        90, 124, 121,  54,  58,  91,  97,  73,  98,  92, 150,  55,  57,\n",
       "        46, 118, 112, 131, 136,  83, 125,  80, 123, 127, 114, 140, 115,\n",
       "       104])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return unique values in a series as ndarray\n",
    "city_mpg.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f0f0b9-2305-4746-9b30-e69758c88f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15     4503\n",
       "18     4053\n",
       "17     4035\n",
       "16     3975\n",
       "19     3012\n",
       "       ... \n",
       "127       1\n",
       "114       1\n",
       "140       1\n",
       "115       1\n",
       "104       1\n",
       "Name: city08, Length: 105, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a series containing counts of unique values\n",
    "city_mpg.value_counts(dropna=False)  # by default, dropna=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20034f31-94aa-4a49-bdf1-c41e67097031",
   "metadata": {},
   "source": [
    "### The _.agg()_ function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065af75d-33ae-46b7-a63f-b4e1fea97258",
   "metadata": {},
   "source": [
    "The `.agg()` function can be used to perform multiple aggregate operations (you can also define your own aggregate functions) on a series object at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b099dd-25ae-4941-8d50-b624d1d51539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min                 6\n",
       "idxmin           7901\n",
       "max               150\n",
       "idxmax          31256\n",
       "mean        18.369045\n",
       "std          7.905886\n",
       "var         62.503036\n",
       "quantile         17.0\n",
       "all              True\n",
       "sum            755776\n",
       "Name: city08, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_mpg.agg(\n",
    "    [\"min\", \"idxmin\", \"max\", \"idxmax\", \"mean\", \"std\", \"var\", \"quantile\", \"all\", \"sum\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0727ccc-aa34-4bf1-ab1e-957bf1f267a1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf18a7-09e3-4b1e-a622-1fb169c57a23",
   "metadata": {},
   "source": [
    "To learn about all the available aggregate functions see the documentation @ https://pandas.pydata.org/pandas-docs/stable/reference/series.html#computations-descriptive-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43602c69-054c-4dc3-8bff-79fa00ed0443",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "----------------------------\n",
    "## Data type casting \n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb58136-d947-4172-a712-c6a4969bd31c",
   "metadata": {},
   "source": [
    "It is often the case that we need to convert between data types, usually for better performance (more manipulation\n",
    "options or use less memory) or some other reasons. Whatever may be the case Pandas provides a very useful function namely, `astype(dtype)` for converting data type of a Series or DataFrame object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b5fa69-b15a-405e-bdab-2a89db06dd79",
   "metadata": {},
   "source": [
    "> Some of the major datatypes available in pandas include: \n",
    "\n",
    "    object, int, float, bool, datetime, category etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f2ce2-148f-4dbd-b66b-290e2d492655",
   "metadata": {},
   "source": [
    "Refer to this article @ https://pbpython.com/pandas_dtypes.html for a basic idea on the pandas data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776a918-06c0-4301-b30d-954f0a64d362",
   "metadata": {},
   "source": [
    "- Inspecting numerical limits of different integer and float types "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e495e9-f7c7-4310-97f4-8e214f6c93a9",
   "metadata": {},
   "source": [
    "The **default numeric type is 8 bytes wide (64 bits, ie int64 or float64)**. If you can use a narrower type, you can cut back on memory usage, giving you memory to process more data. You can use NumPy to inspect limits on integer and float types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a856147d-f5e7-4cc9-81c2-b2686b03b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for int16\n",
      "---------------------------------------------------------------\n",
      "min = -32768\n",
      "max = 32767\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for uint8\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 255\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# integer\n",
    "print(np.iinfo(np.int16))  # or, np.iinfo(\"int16\")\n",
    "print(np.iinfo(np.uint8))  # or, np.iinfo(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "137af9df-c46b-43d1-b690-8a15a752911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for float16\n",
      "---------------------------------------------------------------\n",
      "precision =   3   resolution = 1.00040e-03\n",
      "machep =    -10   eps =        9.76562e-04\n",
      "negep =     -11   epsneg =     4.88281e-04\n",
      "minexp =    -14   tiny =       6.10352e-05\n",
      "maxexp =     16   max =        6.55040e+04\n",
      "nexp =        5   min =        -max\n",
      "smallest_normal = 6.10352e-05   smallest_subnormal = 5.96046e-08\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# float\n",
    "print(np.finfo(\"float16\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5081d73d-8bce-4cb7-9e46-5f9bb8893f00",
   "metadata": {},
   "source": [
    "- Checking memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5590c-a42c-41de-8495-c5ec59f0cdfa",
   "metadata": {},
   "source": [
    "To check how much memory the values of a Series or DataFrame is consuming we can use the `nbytes` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df999628-11cc-41cb-9333-26bd97a7e239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246864"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, the data in city_mpg Series was stored as int64 type\n",
    "\n",
    "# the max value in our seires object is 150\n",
    "# so, we can't use int8 but we can cast to int16\n",
    "\n",
    "# to see how much space is saved\n",
    "city_mpg.nbytes - city_mpg.astype(\"int16\").nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb0729-1e4b-4d26-b28e-b06ea6156ea0",
   "metadata": {},
   "source": [
    "Using `.nbytes` with object types only shows how much memory the Pandas object is taking. The **make** in the vehicles dataset provides the manufacturer name (strings) and is stored as an object. To get the amount of memory that includes the strings, we need to use the `.memory_usage` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1747473-933f-4a96-a32e-348f38781d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the make column as a series\n",
    "manufac = df.make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dbd9567-6b46-4aab-90a7-ffbebfcb8491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Alfa Romeo\n",
       "1       Ferrari\n",
       "2         Dodge\n",
       "Name: make, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manufac.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d437ac04-d930-45fb-829c-03d70e0fef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329152"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining memory usage with nbbytes function\n",
    "manufac.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b092780c-5a51-41c4-a667-fe94b2f05afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2606395"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining memory usage with memory_usage function\n",
    "manufac.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4a529-6ef1-4ca0-b289-f1d2d879da55",
   "metadata": {},
   "source": [
    "The value of _.nbytes_ is just the memory that the data is using and not the ancillary parts of the Series. The _.memory_usage_ includes the index memory and can include the contribution from object types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c740b-fc4f-4c5a-aa6b-699189a20f76",
   "metadata": {},
   "source": [
    "- **String and Category type**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a521d54f-fa5b-4cf5-ace9-3e55b4f0f8df",
   "metadata": {},
   "source": [
    "A `categorical` series is useful for string data and can result in large memory savings. This is because for categorical data, instead of using python `string` to store the values, pandas optimizes it so that **repeating values are not duplicated**. You **still have all of the functionality found off of the .str attribute.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72b1d9-58ca-42fc-abdf-3cf3b4e0ff06",
   "metadata": {},
   "source": [
    "For example, if we convert the make column from the vehicles dataframe i.e, the manufac series to category object, this will have much more improved memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d15fb8e8-ae21-4c4e-87e7-860d8087ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the make column as categorical object\n",
    "manufac_cat = df.make.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14dbff7e-603e-45ae-9ce0-1aeed8a13cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Alfa Romeo\n",
       "1       Ferrari\n",
       "2         Dodge\n",
       "Name: make, dtype: category\n",
       "Categories (136, object): ['AM General', 'ASC Incorporated', 'Acura', 'Alfa Romeo', ..., 'Volvo', 'Wallace Environmental', 'Yugo', 'smart']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manufac_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77576bdc-47a8-41f2-9a3a-ed312ab84409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241608"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the memory footprint\n",
    "manufac.memory_usage() - manufac_cat.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94ca01-e613-4f41-a36a-bc226958f7fe",
   "metadata": {},
   "source": [
    "- **Custom & ordered categories**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d2bd6-9d6b-4fe3-9ec4-b33792391058",
   "metadata": {},
   "source": [
    "To define custom categories we need to use the `pd.Categorical(values, categories, ordered=False)` function. And, to have the categories in order we need to set, _ordered = True_\n",
    "\n",
    "**Note:**\n",
    "1. a Categorical **might have an order**, but numerical operations (additions, divisions, ...) are not possible.    \n",
    "2. Assigning values **outside of categories** will result in replacing the value with **NaN** in the series object.\n",
    "3. Order is defined by the order of the categories, **not lexical order** of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e86ebf-503d-4d51-bc4e-351999956dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values\n",
    "vals = manufac\n",
    "# categories\n",
    "cat = manufac.unique()\n",
    "\n",
    "# to have an ordered category we just need to set, ordered = True\n",
    "ord_manufac = pd.Categorical(values=vals, categories=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6150ad4-f065-4417-9be5-d2e3a9af19b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alfa Romeo', 'Ferrari', 'Dodge', 'Dodge', 'Subaru', ..., 'Subaru', 'Subaru', 'Subaru', 'Subaru', 'Subaru']\n",
       "Length: 41144\n",
       "Categories (136, object): ['Alfa Romeo', 'Ferrari', 'Dodge', 'Subaru', ..., 'Consulier Industries Inc', 'Goldacre', 'Isis Imports Ltd', 'PAS Inc - GMC']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_manufac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ba8ef-523b-4e63-bf5e-ec73ea3447f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manipulation methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338d791-22d5-415b-bd83-eab01952332d",
   "metadata": {},
   "source": [
    "When working on a dataset, usually the most used methods are some kind of manipulation methods. These are specially useful when we are cleaning up our dataset or, are exploring it to understand it better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210e667-f326-4aaa-80ac-514d441c282b",
   "metadata": {},
   "source": [
    "- Applying a custom function to every element of a Series (also works on DataFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d077fa5-1c55-4320-8a82-84c4bfcf11ab",
   "metadata": {},
   "source": [
    "The `apply(func)` method will call the `func` function on every element of a Series. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134102d3-a91a-4da1-a171-7bc371a5e037",
   "metadata": {},
   "source": [
    "This is usually not wise to use since this will dramatically increase the computation time. We already have a wide range of predefined pandas methods and functions for almost all the manipulation operations we can desire. But for some reason or other, if we can't find any suitable methods then we can define our own function and call it using the apply() method. **Note that,** we only need to pass in the name of the function and not call them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a168c84-3439-464e-adcf-721bc6de8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say, we only want to keep the top 5 manufacturers and replace other values with \"Other\" in the manufac Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a095ef6c-2a80-4dca-9bbc-99d6954f00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the custom manipulation function\n",
    "top_5_manufac = manufac.value_counts().index[0:5]\n",
    "\n",
    "\n",
    "def custom_manipulation(val):\n",
    "    if val in top_5_manufac:\n",
    "        return val\n",
    "    else:\n",
    "        return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e1e8d51-73cd-467a-86c9-5833f8f43cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 ms ± 1.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit # magic functions needs to go at the top of the cell\n",
    "\n",
    "# applying the custom_manipulation function on manufac Series\n",
    "custom_manufac = manufac.apply(custom_manipulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9db0b516-8aeb-410c-8c6f-45b67651436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26622,  4003,  3371,  2583,  2494,  2071])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_manufac.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ade85d-3257-4898-b450-6b8446b5c020",
   "metadata": {},
   "source": [
    "- The `where(cond, other)` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b0c210-eae5-4ab0-acfd-5642696aee66",
   "metadata": {},
   "source": [
    "This method **replaces values where the condition is False with corresponding value from 'other'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0decad29-ba72-40b5-ba26-48c8f8f5a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we were to do the same thing as the above example with where() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b37cd20-81f5-4855-a97b-efffc1b60483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ms ± 178 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Series.isin(values) checks Whether elements in Series are contained in `values`\n",
    "manufac.where(cond=manufac.isin(top_5_manufac), other=\"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768b085-121b-420d-9cfd-a91ac190c1ca",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77de01-e284-45c3-bcca-758585682afc",
   "metadata": {},
   "source": [
    "As we can see this is almost 14 times faster than the apply() approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545551b-82d1-4f05-b012-0b4a44b596b2",
   "metadata": {},
   "source": [
    "- The `mask(cond, other)` method **replaces values where the condition is True with corresponding value from 'other'**. It is equivalent to: **where(~cond, other)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c6c5ab-b8e9-4d9d-bf85-62f7fa06830a",
   "metadata": {},
   "source": [
    "- The `clip(lower, upper)` method for handling **outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def4b8b-c18f-41c9-a634-477cc3faa271",
   "metadata": {},
   "source": [
    "This will **replace all values above the upper threshold with the upper value and all values lower than the lower threshold with the lower value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7e5b8-b1d0-4135-b74b-b789957bfe47",
   "metadata": {},
   "source": [
    "Clipping is handy if you have outliers in your data. In the city_mpg series the values ranges from 6 to 150. But, there are only 16 vehicles with city_mpg > 130 and 39 vehicles with city_mpg < 8 out of the total 41144 vehicles. Say, we wanted to clip those entries, we can do that very easily with the clip method. Or say, we wanted to clip the values between the 5% quantile and 95% quantile. We could also do that very easily with the clip method. All this is to say that, this is a very handy tool to use in the right situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b2ba3061-e7bd-448e-8f7d-3c0f83ff0f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower:  8\n",
      "Upper:  120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the first case\n",
    "print(\"Min: \", city_mpg.clip(lower=8, upper=120).min())\n",
    "print(\"Max: \", city_mpg.clip(lower=8, upper=120).max())\n",
    "\n",
    "# see that the values were replaced not dropped\n",
    "len(city_mpg) == len(city_mpg.clip(lower=8, upper=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ceabe83-d109-494e-ade1-81d409d5d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  11 Max:  27\n",
      "5% Quantile:  11.0 95% Quantile:  27.0\n"
     ]
    }
   ],
   "source": [
    "# in the second case\n",
    "quantile_5 = city_mpg.quantile(0.05)\n",
    "quantile_95 = city_mpg.quantile(0.95)\n",
    "\n",
    "print(\n",
    "    \"Min: \",\n",
    "    city_mpg.clip(lower=quantile_5, upper=quantile_95).min(),\n",
    "    \"Max: \",\n",
    "    city_mpg.clip(lower=quantile_5, upper=quantile_95).max(),\n",
    ")\n",
    "print(\"5% Quantile: \", quantile_5, \"95% Quantile: \", quantile_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8badc95-c55a-4206-b8b6-84de9dc71c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bed1000-6be2-4c08-8fa3-73fa8368ef43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e877d40-cd0c-4aab-942f-c799ed6ee296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7668bd76-4432-4396-aee7-26578f3a4d6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Missing values and How to handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "362bddd5-f04f-4878-a32c-915b9b94b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cylinders column has missing values\n",
    "cylinders = df.cylinders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5262fb-5161-420b-8ee1-2e20909befc7",
   "metadata": {},
   "source": [
    "**| Counting the total number of missing values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17650798-bae8-4fce-a57d-91b1b6e36824",
   "metadata": {},
   "source": [
    "The `series.isna()` function detects missing values. An interesting property of the **sum()** method is that it treats True as 1 and False as 0. This property can be used to count the number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "314bbaa0-18ce-457c-a078-36cbcebc444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the series.isna() function detects missing values\n",
    "cylinders.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04347754-4ede-4936-b097-2f15789e7591",
   "metadata": {},
   "source": [
    "**| Let's see for which manufacturers the cylinders value is missing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c449d547-66d0-4942-89c8-9cfa59c5b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean mask for missing values\n",
    "mask_missing = cylinders.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0353d531-9a49-4d83-a86b-7b0145500247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla     74\n",
       "smart     16\n",
       "Ford      15\n",
       "Nissan    14\n",
       "BMW       10\n",
       "Name: make, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manufac[mask_missing].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43d00f8-aeb9-4396-90d8-f8891cb8c40a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a35c3f-43b1-49ba-85a6-a819aab9f33c",
   "metadata": {},
   "source": [
    "Here we can see that most of the cars with missing cylinders values are Teslas. Since Teslas are electric cars this makes sense. **Note:** An alternative way would be to use the `loc` method insted of this boolean masking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb214a-5761-4cb0-8576-73f7de05e346",
   "metadata": {},
   "source": [
    "Now let's discuss how to handle these missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f2c6f-0943-4347-9dab-fe4d49516f60",
   "metadata": {},
   "source": [
    "### _Handling missing values_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adf203d-3261-49e4-a9d7-e59e01001e61",
   "metadata": {},
   "source": [
    "- The `.fillna()` method allows you to specify a replacement value for any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7cd0fad-4b68-40fa-b202-b6a791935ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0     15938\n",
       "6.0     14284\n",
       "8.0      8801\n",
       "5.0       771\n",
       "12.0      626\n",
       "3.0       279\n",
       "0.0       206\n",
       "10.0      170\n",
       "2.0        59\n",
       "16.0       10\n",
       "Name: cylinders, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cylinders.fillna(0).value_counts()  # Doesn't change in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441d96e-16f3-4c70-899a-d4e7f055bd89",
   "metadata": {},
   "source": [
    "**Note that**, in this case it was reasonable to replace the \"nan\" values with \"0\" but it is not always the case. In other scenarios the **.mean(), .median(), .mode()** etc. may come in handy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1f929-67e0-4246-9f9a-57186d13a6b7",
   "metadata": {},
   "source": [
    "- The `.dropna()` method will drop the indexes (i.e, rows) with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "911c10e7-cf1c-440d-9f3e-06e1064cea10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see that 'nan' count of 206 is the number of rows that was dropped\n",
    "len(cylinders) - len(cylinders.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe020dc4-70e6-4efd-a674-ac6725cde3ab",
   "metadata": {},
   "source": [
    "- The `.interpolate()` method will replace 'nan' with interpolation of the values around the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9b461-e681-43c6-be74-1cd521251dc1",
   "metadata": {},
   "source": [
    "This is a very useful method to fill in missing values. For example, this comes in handy if the data is ordered (as time series data often is) and there are holes in the data. But, you have to make sure that the data you are manipulating has a trend that can be captured by interpolation. Otherwise, this may lead to disastarous results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87cd1a2c-7041-4ddd-8042-fc32c303dead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19.0\n",
       "1    20.0\n",
       "2    20.0\n",
       "3    21.0\n",
       "4    22.0\n",
       "5    24.0\n",
       "6    23.0\n",
       "7    24.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say we have a series that captures the [somewhat] upward trend of temp. as the season goes into summer from winter\n",
    "temp = pd.Series([19, 20, 20, None, 22, 24, 23, 24])\n",
    "temp.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55883429-8027-4fda-83f9-aba5c4ab3488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
