{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Import Statements](#toc1_1_)    \n",
    "  - [Importing the data](#toc1_2_)    \n",
    "- [String Manipulation](#toc2_)    \n",
    "    - [*Searching through strings: the `.str.extract()` method*](#toc2_1_1_)    \n",
    "    - [*Replacing text: `.str.replace()` and `<Series>.replace()`*](#toc2_1_2_)    \n",
    "    - [*Splitting text: the `.str.split()` method*](#toc2_1_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=5\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the official documentation on pandas Series objects @ https://pandas.pydata.org/pandas-docs/stable/reference/series.html**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Note:`** We can actually use python built in functions on pandas series objects. i.e., **len, type, dir, in, sum, product, mean, sorted, max, min** etc.\n",
    "\n",
    "Also, the notion of **chaining functions/methods** in pandas is similar to python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[Import Statements](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Importing the data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the many datasets we will use for our examples in this notebook is the `/Data/vehicles.csv.zip` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94351/4195767653.py:2: DtypeWarning: Columns (68,70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Data/vehicles.csv.zip\")\n"
     ]
    }
   ],
   "source": [
    "# read the vehicles.csv dataset\n",
    "df = pd.read_csv(\"Data/vehicles.csv.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of a dataframe can be accessed in various ways. One of which is to use the **dot i.e, ' . ' notation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the city08 and highway08 columns from the vehicles.csv dataset provides information on\n",
    "# miles per gallon usage while driving around in the city and highway respectively.\n",
    "city_mpg = df.city08\n",
    "highway_mpg = df.highway08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The make in the vehicles dataset provides the manufacturer name (strings) and is stored as an object.\n",
    "manufac = df.make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The first thing we should do when we load in a dataset is to check the datatypes of each column and cast each of them to more suitable datatypes. This is to save space and speed up our code execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[String Manipulation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, by default pandas stores string type data as objects. But objects can mean various things such as, python lists, dictionaries or custom classes. Thus to have more flexibility over how we treat and use strings we can convert object type to string with the astype() method. If the strings has low cardinality (few unique values) we can also use categorical type which will decrease the processing time further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manufac_str = manufac.astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The .str accessor provides many string manipulation methods, most of which works similarly to the python string methods. The available string methods with the .str accessor are,**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capitalize',\n",
       " 'casefold',\n",
       " 'cat',\n",
       " 'center',\n",
       " 'contains',\n",
       " 'count',\n",
       " 'decode',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'extract',\n",
       " 'extractall',\n",
       " 'find',\n",
       " 'findall',\n",
       " 'fullmatch',\n",
       " 'get',\n",
       " 'get_dummies',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'len',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'match',\n",
       " 'normalize',\n",
       " 'pad',\n",
       " 'partition',\n",
       " 'removeprefix',\n",
       " 'removesuffix',\n",
       " 'repeat',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'slice',\n",
       " 'slice_replace',\n",
       " 'split',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'wrap',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str_methods for str_methods in dir(manufac.astype(\"string\").str) if str_methods.startswith(\"_\") is False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_1_'></a>[*Searching through strings: the `.str.extract()` method*](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a **dataframe** with the first match from each regular expression capture group (separated by first brackets) in its own column (uses named groups for column names). Returns a **series** if **expand=False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter\n",
       "C    5336\n",
       "B    2796\n",
       "A    1610\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the following regex i.e, (?P<letter>^[A-C]) defines that, the Capture Group is named 'letter'\n",
    "# it will search if any of the character in the list, [ABC] is present at the start of a string Element\n",
    "manufac_str.str.extract(r\"(?P<letter>^[A-C])\", expand=False).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_2_'></a>[*Replacing text: `.str.replace()` and `<Series>.replace()`*](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although both of these methods can perform both of the operations, one should use **.str.replace() to replace substrings and \\<Series>.replace() to replace complete strings.** To replace a substring with \\<Series>.replace() set, regex=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20820           Åutokraft Limited\n",
       "19489    Åvanti Motor Corporation\n",
       "18246    Åvanti Motor Corporation\n",
       "24051              Åzure Dynamics\n",
       "24050              Åzure Dynamics\n",
       "Name: make, dtype: string"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing partial string with .str.replace()\n",
    "manufac_str.str.replace(\"A\", \"Å\").sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20820           Åutokraft Limited\n",
       "19489    Åvanti Motor Corporation\n",
       "18246    Åvanti Motor Corporation\n",
       "24051              Åzure Dynamics\n",
       "24050              Åzure Dynamics\n",
       "Name: make, dtype: string"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing partial string with .replace() method\n",
    "manufac_str.replace(\"A\", \"Å\", regex=True).sort_values().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_1_3_'></a>[*Splitting text: the `.str.split()` method*](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be useful when dealing with survey data that has binned numeric values. By default, the split method will return a series of list of the splited values. But, this is difficult to manipulate. So, what we can do is, set **expand=True** and this will return a DataFrame. Then we can access the individual columns of the dataframe if we wanted a series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of splitting binned data\n",
    "age = pd.Series([\"1-10\", \"11-20\", \"21-30\", \"31-40\", \"41-50\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_df = (\n",
    "    age.astype(dtype=\"string\")\n",
    "    .str.split(\"-\", expand=True)\n",
    "    .rename(columns={0: \"low\", 1: \"high\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  low high\n",
       "0   1   10\n",
       "1  11   20\n",
       "2  21   30\n",
       "3  31   40\n",
       "4  41   50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1    11\n",
       "2    21\n",
       "3    31\n",
       "4    41\n",
       "Name: low, dtype: string"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_low = age_df.low\n",
    "age_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `.str.partition(sep, expand=True)` also works similarly.** It will return a dataframe with 3 columns: the element before the sep, the sep, and the part after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
