{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3dbb4d77-e6ed-45cd-97d0-888f3ff53d67",
   "metadata": {},
   "source": [
    "# Reading data files from different sources and Writing data to different file formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d1e60f0-09b7-4973-89d0-441fd91358df",
   "metadata": {},
   "source": [
    "Although it's great that we can create Series and DataFrame objects with our custom data, in real world we will be mostly working with data that already exists. Also after cleaning up a data file we may like to export the cleaned up data to another file for future uses. This is why knowing how to read and write data files in pandas is very important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf46bff2-3e44-4695-9880-cb4c39a67d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9d25b25",
   "metadata": {},
   "source": [
    "There are a bunch of functions in pandas that deal with ingesting data. They all begin with\n",
    "read_. Similarly, there are analagous exporting methods on the dataframe object. These exporting\n",
    "methods start with .to_."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0c63355-fcbb-4438-ab12-1c21c78cb25a",
   "metadata": {},
   "source": [
    "### Interacting with CSV/TSV files (and other similar filetypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a66c5ee1",
   "metadata": {},
   "source": [
    "- Reading from a **CSV** file: <b> pd.read_csv(filepath, sep, delimiter=None, index_col=None, dtype=None, na_values=None) </b>\n",
    "\n",
    "1. filepath: can be any valid string input defing the path to be file like object i.e, an object that has a read() method. valid url can also be passed.\n",
    "2. sep: separator (e.g. for tsv files, sep='\\t').\n",
    "3. delimiter: alias for separator.\n",
    "4. index_col: int, str, sequence of int / str. Column(s) to use as the row labels of the DataFrame, either given as string name or column index. If a sequence of int / str is given, a MultiIndex is used.\n",
    "5. dtype: data type of the values.\n",
    "6. na_values: additional strings to recognize as NA/NaN."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcd217ec-3d65-41fa-9fab-684efdb48d62",
   "metadata": {},
   "source": [
    "This can also read zip files containing only a single csv/tsv file without the need of extracting. But, if there's multiple files in the zip file then it must be unzipped before use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6998e64",
   "metadata": {},
   "source": [
    "**Note:** One thing to be aware of is that by default, pandas will write the index values in a CSV, but when reading a CSV it will create a new index unless we specify a column for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bc9231-73ba-4a79-8ec7-7af17b0e7f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DAPR</th>\n",
       "      <th>DASF</th>\n",
       "      <th>MDPR</th>\n",
       "      <th>MDSF</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>...</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                STATION         NAME  LATITUDE  LONGITUDE  ELEVATION  DAPR   \n",
       "DATE                                                                         \n",
       "1980-01-01  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN  \\\n",
       "1980-01-02  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-03  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-04  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-05  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "\n",
       "            DASF  MDPR  MDSF  PRCP  ...  SNWD  TMAX  TMIN  TOBS  WT01  WT03   \n",
       "DATE                                ...                                       \n",
       "1980-01-01   NaN   NaN   NaN  0.10  ...  29.0  38.0  25.0  25.0   NaN   NaN  \\\n",
       "1980-01-02   NaN   NaN   NaN  0.43  ...  34.0  27.0  18.0  18.0   NaN   NaN   \n",
       "1980-01-03   NaN   NaN   NaN  0.09  ...  30.0  27.0  12.0  18.0   NaN   NaN   \n",
       "1980-01-04   NaN   NaN   NaN  0.00  ...  30.0  31.0  18.0  27.0   NaN   NaN   \n",
       "1980-01-05   NaN   NaN   NaN  0.00  ...  30.0  34.0  26.0  34.0   NaN   NaN   \n",
       "\n",
       "            WT04  WT05  WT06  WT11  \n",
       "DATE                                \n",
       "1980-01-01   NaN   NaN   NaN   NaN  \n",
       "1980-01-02   NaN   NaN   NaN   NaN  \n",
       "1980-01-03   NaN   NaN   NaN   NaN  \n",
       "1980-01-04   NaN   NaN   NaN   NaN  \n",
       "1980-01-05   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alta_df = pd.read_csv(\"./Data/alta-noaa-1980-2019.csv\", parse_dates=[\"DATE\"]).set_index(\n",
    "    \"DATE\"\n",
    ")\n",
    "alta_df.index.astype(\"datetime64[ns]\")\n",
    "alta_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beec2e7a",
   "metadata": {},
   "source": [
    "- Writing to a **CSV** file: <b>df.to_csv(path_or_buf, sep, na_rep, encoding, date_format)</b>\n",
    "\n",
    "1. path_or_buf : filepath.\n",
    "2. sep : str, delimiter for the output file (default - ',').\n",
    "3. na_rep : str (default ''), Missing data representation.\n",
    "4. mode : str, default 'w', Python write mode.\n",
    "5. encoding: str, formatting to use in the output file. Default, 'utf-8'\n",
    "6. date_format: Format string for datetime format. \n",
    "alta_df.to_csv('/tmp/alta_df.csv', na_rep='nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a668667",
   "metadata": {},
   "outputs": [],
   "source": [
    "alta_df.to_csv(\"./tmp/alta_df.csv\", na_rep=\"nan\")  # be careful, ./tmp not /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cb0f5d6-3874-4445-8734-34d5307d5c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DAPR</th>\n",
       "      <th>DASF</th>\n",
       "      <th>MDPR</th>\n",
       "      <th>MDSF</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>...</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                STATION         NAME  LATITUDE  LONGITUDE  ELEVATION  DAPR   \n",
       "DATE                                                                         \n",
       "1980-01-01  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN  \\\n",
       "1980-01-02  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-03  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-04  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-05  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "\n",
       "            DASF  MDPR  MDSF  PRCP  ...  SNWD  TMAX  TMIN  TOBS  WT01  WT03   \n",
       "DATE                                ...                                       \n",
       "1980-01-01   NaN   NaN   NaN  0.10  ...  29.0  38.0  25.0  25.0   NaN   NaN  \\\n",
       "1980-01-02   NaN   NaN   NaN  0.43  ...  34.0  27.0  18.0  18.0   NaN   NaN   \n",
       "1980-01-03   NaN   NaN   NaN  0.09  ...  30.0  27.0  12.0  18.0   NaN   NaN   \n",
       "1980-01-04   NaN   NaN   NaN  0.00  ...  30.0  31.0  18.0  27.0   NaN   NaN   \n",
       "1980-01-05   NaN   NaN   NaN  0.00  ...  30.0  34.0  26.0  34.0   NaN   NaN   \n",
       "\n",
       "            WT04  WT05  WT06  WT11  \n",
       "DATE                                \n",
       "1980-01-01   NaN   NaN   NaN   NaN  \n",
       "1980-01-02   NaN   NaN   NaN   NaN  \n",
       "1980-01-03   NaN   NaN   NaN   NaN  \n",
       "1980-01-04   NaN   NaN   NaN   NaN  \n",
       "1980-01-05   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./tmp/alta_df.csv\", index_col=\"DATE\", na_values=\"nan\")\n",
    "df.index.astype(\"datetime64[ns]\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b81e0f51",
   "metadata": {},
   "source": [
    "### Interacting with Excel Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29776081",
   "metadata": {},
   "source": [
    "**Note:** You will have to make sure `openpyxl` is installed to use Excel support. Simply installing the pandas library usually will not install full Excel support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7400ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openpyxl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0addc13",
   "metadata": {},
   "source": [
    "- Reading from **Excel** file: **pd.read_excel(io, sheet_name, header, names, index_col, usecols, dtype, na_values, parse_dates)**\n",
    "\n",
    "1. io : str, path object, or file-like object.\n",
    "2. sheet_name : str, int, list, or None, default 0 (i.e, 1st sheet as a DataFrame).\n",
    "    - Strings are used for sheet names. \n",
    "    - Integers are used in zero-indexed sheet positions (chart sheets do not count as a sheet position).\n",
    "    - Lists of strings/integers are used to request multiple sheets.\n",
    "    - Specify None to get all worksheets.\n",
    "3. header : int, list of int, default 0. Row (0-indexed) to use for the column labels of the parsed DataFrame. If a list of integers is passed those row positions will be combined into a MultiIndex.\n",
    "4. names : array-like, default None. List of column names to use. If file contains no header row, then you should explicitly pass header=None.\n",
    "5. index_col : int, list of int, default None. Column (0-indexed) to use as the row labels of the DataFrame. If a subset of data is selected with usecols, index_col is based on the subset.\n",
    "6. usecols : str, list-like, or callable, default None.\n",
    "7. dtype : Type name or dict of column -> type, default None. \n",
    "8. na_values: Additional values to treat as NaN.\n",
    "9. parse_dates: Columns to treat as datetime objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db083eda",
   "metadata": {},
   "source": [
    "- Writing to **Excel** file: **df.to_excel(excel_writer, sheet_name, na_rep, columns)**\n",
    "\n",
    "1. excel_writer : To write a single object to an Excel .xlsx file it is only necessary to specify a target file name. To write to multiple sheets it is necessary to create an `ExcelWriter` object with a target file name, and specify a sheet in the file to write to.\n",
    "2. sheet_name : Name of sheet which will contain DataFrame.\n",
    "3. na_rep : str (default ''), Missing data representation.\n",
    "4. columns : sequence or list of str, optional. Columns to write."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ce54b5e",
   "metadata": {},
   "source": [
    "**Note:** If there are any timezone aware datetime object in the dataframe we will first need to strip the timezone information using, `df.datetime_col.dt.tz_convert(tz=None)` before exporting to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fd95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing alta_df data of 2012 in a sheet named '2012' and data of 2013 in a sheet named '2013'\n",
    "\n",
    "Writer = pd.ExcelWriter(\"./tmp/alta_df.xlsx\")\n",
    "\n",
    "alta_df_2012 = alta_df[\n",
    "    alta_df.index.year == 2012\n",
    "]  # or, alta_df.loc['2012': '2012-12-31']\n",
    "alta_df_2013 = alta_df[alta_df.index.year == 2013]\n",
    "\n",
    "alta_df_2012.to_excel(excel_writer=Writer, sheet_name=\"2012\")\n",
    "alta_df_2013.to_excel(excel_writer=Writer, sheet_name=\"2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6aa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c68b33fb54bb59552268eca97cce0a66d93ba1e1c3c0870be37ac7a47ccc96a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
