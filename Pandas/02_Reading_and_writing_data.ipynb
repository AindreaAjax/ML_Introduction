{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0863538c",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Interacting with CSV/TSV files (and other similar filetypes)](#toc1_1_)    \n",
    "- [Interacting with Excel Files](#toc1_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=4\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b36cc",
   "metadata": {},
   "source": [
    "# Reading data from different sources and Writing data to different file formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca5a6a5",
   "metadata": {},
   "source": [
    "Although it's great that we can create Series and DataFrame objects with our custom data, but in practice we will mostly be working with data that already exists. Also after cleaning up a data file we may like to export the cleaned up data to another file for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf46bff2-3e44-4695-9880-cb4c39a67d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a21070",
   "metadata": {},
   "source": [
    "There are a bunch of functions in pandas that deal with ingesting data. They all begin with\n",
    "`read_`. Similarly, there are analagous exporting methods on the dataframe object. These exporting\n",
    "methods start with `.to_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ced08",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[Interacting with CSV/TSV files (and other similar filetypes)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087da09",
   "metadata": {},
   "source": [
    "> Reading from a **CSV** file: `pd.read_csv(filepath, sep, delimiter=None, index_col=None, dtype=None, na_values=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae2890",
   "metadata": {},
   "source": [
    "<u>Function Parameters</u>\n",
    "\n",
    "- `filepath:` Path to the file to read. valid url can also be passed.\n",
    "- `sep:` Separator (e.g. for tsv files, sep='\\t'). Separators longer than 1 character and different from '\\s+' will be interpreted as regular expressions.\n",
    "- `index_col:` Column(s) to use as the row labels of the DataFrame, either given as string (name) or column index. If a sequence of int / str is given, a MultiIndex is used.\n",
    "- `dtype:` Data type of the values.\n",
    "- `na_values:` Additional strings to recognize as NA/NaN.\n",
    "- `parse_dates:` The behavior is as follows --\n",
    "    - bool. If True -> try parsing the index.\n",
    "    - list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3 each as a separate date column.\n",
    "    - list of list. e.g. If [[1, 3]] -> combine columns 1 and 3 and parse as a single date column.\n",
    "    - dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call result ‘foo’\n",
    "- `date_format:` Format to use for parsing dates. \n",
    "- `chunksize:` Define it to load the data in chunks instead of the whole thing at once. Specially useful for large files. If specified, returns an iterator where chunksize is the number of rows to include in each chunk (note that, each chunk is a dataframe). We can loop over this iterator to process the data in chunks. e.g. `for chunk in pd.read_csv('data.csv', chunksize=1000): process(chunk)`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcd217ec-3d65-41fa-9fab-684efdb48d62",
   "metadata": {},
   "source": [
    "This can also read zip files containing only a single csv/tsv file without the need of extracting. But, if there's multiple files in the zip file then it must be unzipped before use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6998e64",
   "metadata": {},
   "source": [
    "**Note:** One thing to be aware of is that by default, pandas will write the index values in a CSV, but when reading a CSV it will create a new index unless we specify a column for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5bc9231-73ba-4a79-8ec7-7af17b0e7f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DAPR</th>\n",
       "      <th>DASF</th>\n",
       "      <th>MDPR</th>\n",
       "      <th>MDSF</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>...</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                STATION         NAME  LATITUDE  LONGITUDE  ELEVATION  DAPR  \\\n",
       "DATE                                                                         \n",
       "1980-01-01  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-02  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-03  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-04  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-05  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "\n",
       "            DASF  MDPR  MDSF  PRCP  ...  SNWD  TMAX  TMIN  TOBS  WT01  WT03  \\\n",
       "DATE                                ...                                       \n",
       "1980-01-01   NaN   NaN   NaN  0.10  ...  29.0  38.0  25.0  25.0   NaN   NaN   \n",
       "1980-01-02   NaN   NaN   NaN  0.43  ...  34.0  27.0  18.0  18.0   NaN   NaN   \n",
       "1980-01-03   NaN   NaN   NaN  0.09  ...  30.0  27.0  12.0  18.0   NaN   NaN   \n",
       "1980-01-04   NaN   NaN   NaN  0.00  ...  30.0  31.0  18.0  27.0   NaN   NaN   \n",
       "1980-01-05   NaN   NaN   NaN  0.00  ...  30.0  34.0  26.0  34.0   NaN   NaN   \n",
       "\n",
       "            WT04  WT05  WT06  WT11  \n",
       "DATE                                \n",
       "1980-01-01   NaN   NaN   NaN   NaN  \n",
       "1980-01-02   NaN   NaN   NaN   NaN  \n",
       "1980-01-03   NaN   NaN   NaN   NaN  \n",
       "1980-01-04   NaN   NaN   NaN   NaN  \n",
       "1980-01-05   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alta_df = pd.read_csv(\"./Data/alta-noaa-1980-2019.csv\", parse_dates=[\"DATE\"]).set_index(\n",
    "    \"DATE\"\n",
    ")\n",
    "alta_df.index.astype(\"datetime64[ns]\")\n",
    "alta_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beec2e7a",
   "metadata": {},
   "source": [
    "> Writing to a **CSV** file: `df.to_csv(path_or_buf, sep, na_rep, encoding, date_format)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d76f0f",
   "metadata": {},
   "source": [
    "<u>Function Parameters</u>\n",
    "\n",
    "- path_or_buf : filepath.\n",
    "- sep : delimiter for the output file (str, default `,`).\n",
    "- na_rep : Missing data representation (str, default `''`).\n",
    "- mode : Python write mode (str, default `w`).\n",
    "- encoding: formatting to use in the output file (str, default `utf-8`)\n",
    "- date_format: format string for datetime format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a668667",
   "metadata": {},
   "outputs": [],
   "source": [
    "alta_df.to_csv(\"./tmp/alta_df.csv\", na_rep=\"nan\")  # be careful, ./tmp not /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df90e5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DAPR</th>\n",
       "      <th>DASF</th>\n",
       "      <th>MDPR</th>\n",
       "      <th>MDSF</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>...</th>\n",
       "      <th>SNWD</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TOBS</th>\n",
       "      <th>WT01</th>\n",
       "      <th>WT03</th>\n",
       "      <th>WT04</th>\n",
       "      <th>WT05</th>\n",
       "      <th>WT06</th>\n",
       "      <th>WT11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>USC00420072</td>\n",
       "      <td>ALTA, UT US</td>\n",
       "      <td>40.5905</td>\n",
       "      <td>-111.6369</td>\n",
       "      <td>2660.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                STATION         NAME  LATITUDE  LONGITUDE  ELEVATION  DAPR  \\\n",
       "DATE                                                                         \n",
       "1980-01-01  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-02  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-03  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-04  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "1980-01-05  USC00420072  ALTA, UT US   40.5905  -111.6369     2660.9   NaN   \n",
       "\n",
       "            DASF  MDPR  MDSF  PRCP  ...  SNWD  TMAX  TMIN  TOBS  WT01  WT03  \\\n",
       "DATE                                ...                                       \n",
       "1980-01-01   NaN   NaN   NaN  0.10  ...  29.0  38.0  25.0  25.0   NaN   NaN   \n",
       "1980-01-02   NaN   NaN   NaN  0.43  ...  34.0  27.0  18.0  18.0   NaN   NaN   \n",
       "1980-01-03   NaN   NaN   NaN  0.09  ...  30.0  27.0  12.0  18.0   NaN   NaN   \n",
       "1980-01-04   NaN   NaN   NaN  0.00  ...  30.0  31.0  18.0  27.0   NaN   NaN   \n",
       "1980-01-05   NaN   NaN   NaN  0.00  ...  30.0  34.0  26.0  34.0   NaN   NaN   \n",
       "\n",
       "            WT04  WT05  WT06  WT11  \n",
       "DATE                                \n",
       "1980-01-01   NaN   NaN   NaN   NaN  \n",
       "1980-01-02   NaN   NaN   NaN   NaN  \n",
       "1980-01-03   NaN   NaN   NaN   NaN  \n",
       "1980-01-04   NaN   NaN   NaN   NaN  \n",
       "1980-01-05   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./tmp/alta_df.csv\", index_col=\"DATE\", na_values=\"nan\")\n",
    "df.index.astype(\"datetime64[ns]\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f47e21d",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[Interacting with Excel Files](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1256ccd",
   "metadata": {},
   "source": [
    "**Note:** You will have to make sure `openpyxl` is installed to use Excel support. Simply installing the pandas library usually will not install full Excel support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7400ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openpyxl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0addc13",
   "metadata": {},
   "source": [
    "> Reading from **Excel** file: `pd.read_excel(io, sheet_name, header, names, index_col, usecols, dtype, na_values, parse_dates)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c2aee",
   "metadata": {},
   "source": [
    "<u>Function Parameters</u>\n",
    "- io : filepath.\n",
    "- sheet_name : default 0 (i.e, 1st sheet as a DataFrame). You can any of the following,\n",
    "    - str: Strings are used for sheet names. \n",
    "    - int: Integers are used in zero-indexed sheet positions (chart sheets do not count as a sheet position).\n",
    "    - Lists of strings/integers are used to request multiple sheets.\n",
    "    - None: Specify None to get all worksheets.\n",
    "- header : Row (0-indexed) to use for the column labels of the parsed DataFrame (int, default 0). If a list of integers is passed those row positions will be combined into a MultiIndex.\n",
    "- names : List of column names to use. If file contains no header row, then you should explicitly pass header=None.\n",
    "- index_col : Column (0-indexed) to use as the row labels of the DataFrame (int, default None). If a subset of data is selected with usecols, index_col is based on the subset.\n",
    "- usecols : str, list-like, or callable, default None.\n",
    "- dtype : Type name or, dict of {column: type}, default None. \n",
    "- na_values: Additional values to treat as NaN.\n",
    "- parse_dates: Columns to treat as datetime objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db083eda",
   "metadata": {},
   "source": [
    "> Writing to **Excel** file: `df.to_excel(excel_writer, sheet_name, na_rep, columns)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72ae18",
   "metadata": {},
   "source": [
    "<u>Function Parameters</u>\n",
    "- excel_writer : To write a single object to an Excel .xlsx file it is only necessary to specify a target file name. To write to multiple sheets it is necessary to create an `ExcelWriter` object with a target file name, and specify a sheet in the file to write to.\n",
    "- sheet_name : Name of sheet which will contain the DataFrame.\n",
    "- na_rep : Missing data representation (str, default `''`).\n",
    "- columns : Columns to write (optional, sequence or list of str)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ce54b5e",
   "metadata": {},
   "source": [
    "**Note:** If there are any timezone aware datetime object in the dataframe we will first need to strip the timezone information using, `df.datetime_col.dt.tz_convert(tz=None)` before exporting to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4fd95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing alta_df data of 2012 in a sheet named '2012' and data of 2013 in a sheet named '2013'\n",
    "\n",
    "Writer = pd.ExcelWriter(\"./tmp/alta_df.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "alta_df_2012 = alta_df[\n",
    "    alta_df.index.year == 2012\n",
    "]  # or, alta_df.loc['2012': '2012-12-31']\n",
    "alta_df_2013 = alta_df[alta_df.index.year == 2013]\n",
    "\n",
    "alta_df_2012.to_excel(excel_writer=Writer, sheet_name=\"2012\")\n",
    "alta_df_2013.to_excel(excel_writer=Writer, sheet_name=\"2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211fa30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c68b33fb54bb59552268eca97cce0a66d93ba1e1c3c0870be37ac7a47ccc96a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
